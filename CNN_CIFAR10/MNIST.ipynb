{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "colab": {
      "name": "DeepLearning_assignment03.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishabhm4/Densenet---Keras/blob/master/CNN_CIFAR10/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywA6tkGIqowB",
        "colab_type": "text"
      },
      "source": [
        "## CNN on CIFAR10 and MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi1ngG0HqowD",
        "colab_type": "code",
        "colab": {},
        "outputId": "52a9700e-1ca2-47d1-c89e-9faa9c083ea0"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRRP2G3BqowI",
        "colab_type": "text"
      },
      "source": [
        "##  CIFAR image(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyIgn4x4qowI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28rdydNbqowL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = tf.data.Dataset.from_tensor_slices(\n",
        "    (train_images.reshape([-1, 32,32,3]).astype(np.float32) / 255, train_labels.astype(np.int32)))\n",
        "data = data.shuffle(buffer_size=40000).batch(128).repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6obrM46qowO",
        "colab_type": "code",
        "colab": {},
        "outputId": "2e8dc7ee-516b-4799-93c7-e63019f24c9a"
      },
      "source": [
        "print(train_labels[100])\n",
        "plt.imshow(train_images[100], cmap=\"Greys_r\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x1ffb8949490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ7ZtVk4qowR",
        "colab_type": "text"
      },
      "source": [
        "####  the model using 'keras.layers'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqKWcSZOqowR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_steps = 1500\n",
        "\n",
        "layer_list = [ tf.keras.layers.Conv2D(filters = 64,kernel_size=3,padding='same',activation=tf.nn.relu),\n",
        "              tf.keras.layers.Conv2D(filters = 64,kernel_size=3,padding='same',activation=tf.nn.relu),\n",
        "               tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2),\n",
        "              tf.keras.layers.Dropout(0.5),\n",
        "              \n",
        "              tf.keras.layers.Conv2D(filters=128,kernel_size=3,padding='same',activation=tf.nn.relu),\n",
        "               tf.keras.layers.Conv2D(filters=128,kernel_size=3,padding='same',activation=tf.nn.relu),\n",
        "               tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2),\n",
        "              tf.keras.layers.Dropout(0.5),\n",
        "              \n",
        "               tf.keras.layers.Conv2D(filters=128,kernel_size=3,padding='same',activation=tf.nn.relu),\n",
        "               tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2),\n",
        "                    \n",
        "              \n",
        "              tf.keras.layers.Conv2D(filters=256,kernel_size=3,padding='same',activation=tf.nn.relu),\n",
        "               tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2),\n",
        "              \n",
        "              tf.keras.layers.Flatten(),\n",
        "              tf.keras.layers.Dense(10,activation='softmax')]  \n",
        "model = tf.keras.Sequential(layer_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lWOsjLQqowU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = tf.optimizers.Adam(0.001)\n",
        "# from_logits = True!! #neverforget\n",
        "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxjB8hwbqowX",
        "colab_type": "code",
        "colab": {},
        "outputId": "e0ef5625-4c96-4d3c-bc33-b7b44aa17e4b"
      },
      "source": [
        "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "for step, (img_batch, lbl_batch) in enumerate(data):\n",
        "    if step > train_steps:\n",
        "        break\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(img_batch)\n",
        "        # loss format is generally: first argument targets, second argument outputs\n",
        "        xent = loss_fn(lbl_batch, logits)\n",
        "\n",
        "    # if you didn't build the model, it is important that you get the variables\n",
        "    # AFTER the model has been called the first time\n",
        "    varis = model.trainable_variables\n",
        "    grads = tape.gradient(xent, varis)\n",
        "      \n",
        "    opt.apply_gradients(zip(grads, varis))\n",
        "    \n",
        "    train_acc_metric(lbl_batch, logits)\n",
        "    \n",
        "    if not step % 100:\n",
        "        # this is different from before. there, we only evaluated accuracy\n",
        "        # for one batch. Now, we always average over 100 batches\n",
        "        print(\"Loss: {} Accuracy: {}\".format(xent, train_acc_metric.result()))\n",
        "        train_acc_metric.reset_states()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 2.3024916648864746 Accuracy: 0.078125\n",
            "Loss: 2.2120609283447266 Accuracy: 0.19617187976837158\n",
            "Loss: 2.1037721633911133 Accuracy: 0.28187501430511475\n",
            "Loss: 2.1298694610595703 Accuracy: 0.3235156238079071\n",
            "Loss: 2.1421315670013428 Accuracy: 0.33218318223953247\n",
            "Loss: 2.0674142837524414 Accuracy: 0.3639843761920929\n",
            "Loss: 2.0027928352355957 Accuracy: 0.37953126430511475\n",
            "Loss: 2.0276436805725098 Accuracy: 0.42476561665534973\n",
            "Loss: 2.031627655029297 Accuracy: 0.4427540898323059\n",
            "Loss: 1.9995372295379639 Accuracy: 0.462890625\n",
            "Loss: 1.9845643043518066 Accuracy: 0.47929686307907104\n",
            "Loss: 1.9684754610061646 Accuracy: 0.4881249964237213\n",
            "Loss: 1.9910218715667725 Accuracy: 0.5221925973892212\n",
            "Loss: 1.9158459901809692 Accuracy: 0.5106250047683716\n",
            "Loss: 1.9103682041168213 Accuracy: 0.5484374761581421\n",
            "Loss: 1.8779425621032715 Accuracy: 0.5567968487739563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJDo8nTKqowa",
        "colab_type": "text"
      },
      "source": [
        "#### Sanity check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AzMhF1jqowa",
        "colab_type": "code",
        "colab": {},
        "outputId": "e05c079f-ab0d-4eac-d0a4-19a963842918"
      },
      "source": [
        "test_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (test_images.reshape([-1, 32,32,3]).astype(np.float32) / 255, test_labels.astype(np.int32))).batch(128)\n",
        "\n",
        "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "for img_batch, lbl_batch in test_data:\n",
        "    test_acc_metric(lbl_batch, model(img_batch))\n",
        "print(\"Test acc: {}\".format(test_acc_metric.result()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test acc: 0.5756999850273132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7yFbgBTqowd",
        "colab_type": "text"
      },
      "source": [
        "## Methods we tried\n",
        "\n",
        "- We tried combination of valid and same padding with the same configuration but the accuracy was lower \n",
        "- Used weight dropout, which resulted in increase in accuracy\n",
        "- When using without activation function in the output layer the accuracy was around ~77% (1500) but with softmax function it signifcantly decreased to ~56% (train accuracy)\n",
        "- Used Adam as an optimizer instead of Stochastic Gradient descent which resulted in ~10% increase in accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTDKdrdwqowd",
        "colab_type": "code",
        "colab": {},
        "outputId": "ade30007-f0f1-4881-cad1-8b6ad1100a79"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              multiple                  1792      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            multiple                  36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) multiple                  0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            multiple                  73856     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            multiple                  147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            multiple                  147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            multiple                  295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  10250     \n",
            "=================================================================\n",
            "Total params: 713,162\n",
            "Trainable params: 713,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn5EtTyZqowg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdsYpKXtqowi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "687rSXSaqowm",
        "colab_type": "text"
      },
      "source": [
        "## MNIST dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJrMzqLwqowm",
        "colab_type": "code",
        "colab": {},
        "outputId": "be5d614e-8cca-4f1d-fd1b-4548769b62d2"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "#(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "print(train_labels[0])\n",
        "plt.imshow(train_images[0], cmap=\"Greys_r\")\n",
        "\n",
        "# first difference: data is not reshaped to 784 anymore, but 28x28x1\n",
        "# note the 1 color channel!! this is important\n",
        "data = tf.data.Dataset.from_tensor_slices(\n",
        "    (train_images.reshape([-1, 28, 28, 1]).astype(np.float32) / 255, train_labels.astype(np.int32)))\n",
        "data = data.shuffle(buffer_size=60000).batch(128).repeat()\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (test_images.reshape([-1, 28, 28, 1]).astype(np.float32) / 255, test_labels.astype(np.int32))).batch(10000)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8NM2JEIqowp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_steps=1000\n",
        "\n",
        "layer_list =[\n",
        "    tf.keras.layers.Conv2D(128, 3, padding='valid', activation='relu', input_shape=(28, 28 ,1)),\n",
        "     tf.keras.layers.MaxPooling2D(pool_size=(2,2),strides=2),\n",
        "     tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "     tf.keras.layers.MaxPooling2D(pool_size=(2,2),strides=2),\n",
        "     tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "     tf.keras.layers.MaxPooling2D(pool_size=(2,2),strides=2),\n",
        "     tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(10)]\n",
        "   # Dense(1)]\n",
        "model = tf.keras.Sequential(layer_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP6e-b2nqowr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile model using accuracy to measure model performance\n",
        "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Adam makes things much smoother\n",
        "opt = tf.optimizers.Adam(0.01)\n",
        "# from_logits = True!! #neverforget\n",
        "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQj8ICUaqowu",
        "colab_type": "code",
        "colab": {},
        "outputId": "e553733c-a219-4c84-9efd-fe56946d9e23"
      },
      "source": [
        "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "for step, (img_batch, lbl_batch) in enumerate(data):\n",
        "    if step > train_steps:\n",
        "        break\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(img_batch)\n",
        "        # loss format is generally: first argument targets, second argument outputs\n",
        "        xent = loss_fn(lbl_batch, logits)\n",
        "\n",
        "    # if you didn't build the model, it is important that you get the variables\n",
        "    # AFTER the model has been called the first time\n",
        "    varis = model.trainable_variables\n",
        "    grads = tape.gradient(xent, varis)\n",
        "      \n",
        "    opt.apply_gradients(zip(grads, varis))\n",
        "    \n",
        "    train_acc_metric(lbl_batch, logits)\n",
        "    \n",
        "    if not step % 100:\n",
        "        # this is different from before. there, we only evaluated accuracy\n",
        "        # for one batch. Now, we always average over 100 batches\n",
        "        print(\"Loss: {} Accuracy: {}\".format(xent, train_acc_metric.result()))\n",
        "        train_acc_metric.reset_states()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 2.2913389205932617 Accuracy: 0.109375\n",
            "Loss: 0.1638101041316986 Accuracy: 0.7582031488418579\n",
            "Loss: 0.06666335463523865 Accuracy: 0.9578906297683716\n",
            "Loss: 0.12947236001491547 Accuracy: 0.9654687643051147\n",
            "Loss: 0.046500422060489655 Accuracy: 0.9739062786102295\n",
            "Loss: 0.07407531887292862 Accuracy: 0.973919153213501\n",
            "Loss: 0.038855329155921936 Accuracy: 0.979687511920929\n",
            "Loss: 0.051047433167696 Accuracy: 0.98046875\n",
            "Loss: 0.03440622240304947 Accuracy: 0.9801562428474426\n",
            "Loss: 0.046908702701330185 Accuracy: 0.9797656536102295\n",
            "Loss: 0.09307347983121872 Accuracy: 0.981203019618988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVs2nuezqoww",
        "colab_type": "code",
        "colab": {},
        "outputId": "b9de1bba-570e-4a6d-888a-ed0841ea19e3"
      },
      "source": [
        "\n",
        "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "for img_batch, lbl_batch in test_data:\n",
        "    test_acc_metric(lbl_batch, model(img_batch))\n",
        "print(\"Test acc: {}\".format(test_acc_metric.result()))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test acc: 0.9858999848365784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O0nyb45qow0",
        "colab_type": "text"
      },
      "source": [
        "#### using MNIST dataset without  'softmax' results in accof 98% while when activation used hardly 57-58% acc is acheived"
      ]
    }
  ]
}